{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEOKtuQB4YuL"
      },
      "source": [
        "### Homework 4\n",
        "Each questions has a grade of 2 points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmF7PeFH1l4Q"
      },
      "source": [
        "(1) A die D has four sides with the following probabilities :\n",
        "p(1) = p(2) = 1/8, p(3) = 1/4, p(4)= 1/2.\n",
        "What is the entropy of this distribution?\n",
        "\n",
        "(A) Calculate the entropy analytically usng the formula\n",
        "\n",
        "(B) Calculate the entropy using Python code"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 1 - A\n",
        "from math import log2\n",
        "p = [1/8,1/8,1/4,1/2]\n",
        "H = -sum([pi * log2(pi) for pi in p])\n",
        "H"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSPMqoN7kkFe",
        "outputId": "aaf99ea5-b295-4ccf-c7a9-31ce6bfc9b74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.75"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obWQGo7B0pmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3709a623-f3d8-4966-ca92-dcb4cffb514f"
      },
      "source": [
        "# Question 1 - B\n",
        "from scipy.stats import entropy\n",
        "p = [1/8,1/8,1/4,1/2]\n",
        "H = entropy(p, base=2)\n",
        "H"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.75"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09xThlnY3TKs"
      },
      "source": [
        "(2) Consider the die D of quesion (1):\n",
        "\n",
        "(A) Which probability distribution of the four sides will maximize the entropy, i.e., find the values of P(1), P(2), P(3), and P(4)? \n",
        "\n",
        "(B) What is the value of the maximum entropy?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq2XzKMS3jEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "848ab47d-7e32-4423-a906-df7e6eaa7897"
      },
      "source": [
        "# Question 2\n",
        "# p(1)=1/4 , p(2)=1/4, p(3)=1/4, p(4)=1/4\n",
        "p = 1/4\n",
        "H = -sum([p * log2(p) for _ in range(4)])\n",
        "H"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8LEvYQ57YXX"
      },
      "source": [
        "(3) A coin C1 has the probability distribution p(T) = p(H) = 1/2\n",
        "Another coin C2 has the probability distribution p(T) = 3/4, p(H) = 1/4\n",
        "What is the relative entropy (Kullback–Leibler divergence ) from C2 to C1?\n",
        "What is the relative entropy (Kullback–Leibler divergence ) from C1 to C2?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3 - A\n",
        "from scipy.stats import entropy\n",
        "c1 = [1/2,1/2]\n",
        "c2 = [3/4,1/4]\n",
        "def CrossEntropy(p, q):\n",
        "\treturn -sum([p[i]*log2(q[i]) for i in range(len(p))])\n",
        "rel_entropy_c2_to_c1 =   CrossEntropy(c1,c2) - entropy(c1,base=2) # DKL(C1|C2) = H(C1,C2) - H(C1)\n",
        "rel_entropy_c2_to_c1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujZApYoplTsF",
        "outputId": "f43f44bd-5ab7-45c8-eb12-c14bd3e2dad9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.20751874963942196"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 3 - B\n",
        "rel_entropy_c1_to_c2 =   CrossEntropy(c2,c1) - entropy(c2,base=2) # DKL(C2|C1) = H(C2,C1) - H(C2)\n",
        "rel_entropy_c1_to_c2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rk0ZFrbRmjHF",
        "outputId": "f4f3ec21-d1fe-4c85-ad8d-45c73559f4a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.18872187554086717"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(4) Suppose we have a source with 5 symbols. The corresponding probabilities are (0.3,0.3,0.2,0.1,0.1).\n",
        "\n",
        "(A) What is the best possible average bits per symbol if we want to compress the source?\n",
        "\n",
        "(B) Give a Huffman coding for the source symbols and calculate the average bits/symbol?"
      ],
      "metadata": {
        "id": "HJf09nu4glcz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4 - A\n",
        "p = [0.3,0.3,0.2,0.1,0.1]\n",
        "#Theoretically, best possible average bits per symbol is given by the entropy\n",
        "theoretical_best_avg_bits_per_symbol = entropy(p,base=2)\n",
        "theoretical_best_avg_bits_per_symbol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZVi8u9qm2dh",
        "outputId": "689c78cf-65f0-46ca-c5bf-01c94921a5c7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.1709505944546685"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Question 4 - B\n",
        "#Practically, the best possible average is given by the Huffman coding.\n",
        "# a1 00\n",
        "# a2 01\n",
        "# a3 10\n",
        "# a4 110\n",
        "# a5 111\n",
        "length_of_huffman_coding = [2,2,2,3,3]\n",
        "avg_bit_per_symbol = sum([length_of_huffman_coding[i]*p[i] for i in range(len(p))])\n",
        "avg_bit_per_symbol"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWUnrnTzoXb-",
        "outputId": "4bd61d67-1283-4dbc-b647-1b7150f2ee6b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.2"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}